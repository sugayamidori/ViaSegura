# ViaSegura - Data & ML Module

> Traffic accident forecasting system using LightGBM and H3 spatial cells

## Table of Contents

- [Overview](#-overview)
- [Architecture](#️-architecture)
- [Installation](#-installation)
- [Execution Pipeline](#-execution-pipeline)
- [Data Structure](#-data-structure)
- [Backend Integration](#-backend-integration)
- [Database](#️-database)
- [GPU/CUDA](#-gpucuda)
- [Configuration](#-configuration)
- [Troubleshooting](#-troubleshooting)

---

##  Overview

This module is responsible for:

1. **Data preparation** – Cleaning, geocoding, and temporal feature generation  
2. **Model training** – LightGBM with temporal validation  
3. **Forecast generation** – Next 12 weeks by H3 cell  
4. **Export** – CSV files ready for backend ingestion  

### Methodology

- **Aggregation**: Weekly (not daily) per H3 cell  
- **Target**: Accident density (Poisson regression)  
- **Features**: Cyclical temporal + lagged historical + vehicle mix  
- **Validation**: Time Series Cross-Validation (5 folds)  
- **Acceleration**: Optional CUDA support  

---

##  Architecture
```
ViaSegura/Data/
├── data/
│ ├── raw/ # Original data
│ │ ├── merged_dataset.csv # CTTU dataset
│ │ └── geocode_cache.json # Coordinate cache
│ └── processed/
│ └── processed_dataset.csv #  Generated by prepare_dataset.py
│
├── src/
│ ├── config/
│ │ └── config.py # Centralized configuration
│ ├── preprocessing/
│ │ ├── data_loader.py # Cleaning + geocoding
│ │ ├── temporal_features.py # Temporal feature engineering
│ │ ├── geocode.py # Extra geocoding utilities
│ │ └── grid.py # Jitter + H3 indexing
│ ├── modeling/
│ │ ├── lgb_model.py # LightGBM
│ │ └── poisson_model.py # Poisson baseline
│ └── utils.py # Helper functions
│
├── backend_export/ #  Generated by main.py
│ ├── models/
│ │ ├── lgb_model.txt # Trained model
│ │ └── mappings.json # Encodings / mappings
│ ├── h3_grid.csv # Cell metadata
│ ├── predictions_weekly.csv # 12-week forecasts
│ ├── heatmap_monthly.csv # Monthly history
│ └── metadata.json # Model info
│
├── prepare_dataset.py # [1] Initial data prep
├── main.py # [2] Training + forecasts
├── requirements.txt
└── README.md
```
##  Installation

### Option 1: Local (CPU)
```bash
# Clone the repository
git clone https://github.com/sugayamidori/ViaSegura.git
cd viasegura/Data

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

### Option 2: Google Colab (GPU)

# Install LightGBM with GPU support
!pip uninstall lightgbm -y --quiet
!pip install lightgbm --config-settings=cmake.define.USE_GPU=ON --quiet

# Clone repository
!git clone https://github.com/sugayamidori/ViaSegura.git
%cd viasegura/Data

# Install dependencies
!pip install -r requirements.txt

# Check GPU
!nvidia-smi

### requirements.txt
```txt
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
lightgbm>=4.0.0
h3>=3.7.6
holidays>=0.35
python-dateutil>=2.8.2
```

---
##  Execution Pipeline

### **Step 1: Prepare Dataset**
```bash
python prepare_dataset.py
```

**O que faz:**
-What it does:

- ✅ Loads raw/merged_dataset.csv
- ✅ Cleans and validates data
- ✅ Applies geocoding
- ✅ Creates temporal features (holiday, weekend, sin/cos)
- ✅ Adds spatial jitter
- ✅ Indexes using H3 (resolution 9)
- ✅ Saves to processed/processed_dataset.csv

**Output:**
```
processed/processed_dataset.csv (71,983 rows, 55 columns)

```

**Estimated time:** 2-5 minutes

---

### **Step 2: Train Model and Generate Forecasts**
```bash
python main.py
```

**What does it do:**
1. ✅ Loads processed dataset
2. ✅ Filters pandemic years (2020–2021)
3. ✅ Aggregates weekly by H3 cell
4. ✅ Creates historical features (lags, moving averages)
5. ✅ Trains LightGBM model with Time Series CV
6. ✅ Performs model decay analysis
7. ✅ Generates autoregressive forecasts (12 weeks)
8. ✅ Exports CSVs for backend integration

**Output:**
```
backend_export/
├── h3_grid.csv              # 2,847 cells
├── predictions_weekly.csv   # 34,164 forcasts (2847 × 12)
├── heatmap_monthly.csv      # Monthly historical data
├── metadata.json            # Metrics + config
└── models/
    └── lgb_model.txt        # Trained model
```

**Estimated time::**
- CPU: ~10-15 minutes
- GPU: ~3-5 minutes 

---

### **Full Pipeline (Colab with GPU)**
```python
# 1.Install Light GBM with GPU
!pip uninstall lightgbm -y --quiet
!pip install lightgbm --config-settings=cmake.define.USE_GPU=ON --quiet

# 2. Clone Repo
!git clone https://github.com/sugayamidori/ViaSegura.git
%cd viasegura/Data

# 3. Install requirements
!pip install -r requirements.txt

# 4. Prep dataset
!python prepare_dataset.py

# 5. Activate GPU
!sed -i "s/USE_GPU = False/USE_GPU = True/" src/config/config.py

# 6. Train and export
!python main.py

# 7. Download files
from google.colab import files
!zip -r backend_export.zip backend_export/
files.download('backend_export.zip')
```

---
##  Data Structure

### **processed_dataset.csv**
| Column | Description |
|--------|--------------|
| `id` | Unique identifier |
| `date` | Reference date |
| `year`, `month`, `week` | Temporal components |
| `weekday` | Day of the week (0=Monday) |
| `is_weekend` | Weekend flag |
| `is_holiday` | National holiday flag |
| `latitude`, `longitude` | Adjusted coordinates (with jitter) |
| `h3_9` | H3 cell at resolution 9 |
| `vehicles_cars`, `vehicles_motorcycles`, ... | Vehicle mix |
| `accidents` | Number of accidents |
| `accidents_density` | Target variable |
| `lag_1w`, `lag_2w`, ... | Weekly lags |
| `rolling_mean_4w` | 4-week moving average |
| `sin_week`, `cos_week` | Cyclical temporal features |

> **Note:** The H3 resolution 9 was chosen because it offers an average radius of ≈ 170 meters, balancing precision and generalization.

---

## Backend Integration

### Output directory: `backend_export/`

| File | Description |
|------|--------------|
| `h3_grid.csv` | List of cells with geographic metadata |
| `predictions_weekly.csv` | 12-week forecasts per H3 cell |
| `heatmap_monthly.csv` | Monthly history for visualization |
| `models/lgb_model.txt` | Trained LightGBM model |
| `models/mappings.json` | Encodings and scalers used |
| `metadata.json` | Model info, RMSE, version, timestamp |

---

### Example: `predictions_weekly.csv`
| h3_9 | week | predicted_density | mean_density | std_density | decay_factor |
|------|------|-------------------|---------------|--------------|---------------|
| 89c2862b62fffff | 2025-06-01 | 0.132 | 0.128 | 0.047 | 0.98 |
| 89c2862b62fffff | 2025-06-08 | 0.118 | 0.128 | 0.047 | 0.96 |
| 89c2862b62fffff | 2025-06-15 | 0.102 | 0.128 | 0.047 | 0.93 |

---

### Example: `h3_grid.csv`
| h3_9 | latitude | longitude | bairro | zone |
|------|-----------|------------|---------|------|
| 89c2862b62fffff | -8.0475 | -34.8769 | Boa Vista | Center |
| 89c2862b67bffff | -8.0521 | -34.8930 | Santo Amaro | North |
| 89c2862b6afffff | -8.0632 | -34.9105 | Madalena | West |

---

### Example: `metadata.json`
```json
{
  "model": "lightgbm_poisson",
  "version": "1.0.0",
  "train_start": "2015-01-01",
  "train_end": "2024-12-31",
  "forecast_weeks": 12,
  "rmse": 0.1925,
  "mae": 0.0641,
  "r2": 0.8727,
  "features": 55,
  "use_gpu": true,
  "created_at": "2025-10-18T15:42:03"
}

##  Model Metrics

### Validation (Time Series CV, 5 folds)
**Results (LightGBM, 5 folds):**

| Metrics        | Mean   |
|----------------|--------|
| MAE            | 0.0433 |
| RMSE           | 0.2341 |
| Poisson Deviance | 0.0293 |

**Results (Poisson baseline, training):**

| Metrics        | Value   |
|----------------|--------|
| MAE            | 0.1347 |
| RMSE           | 0.2991 |
| Poisson Deviance | 0.0615 |


---
